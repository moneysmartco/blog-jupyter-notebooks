{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the SEO Test Setup\n",
    "\n",
    "I.e. checking that the right urls are set up, without going too crazy on testing everything.\n",
    "\n",
    "In brief:\n",
    "\n",
    "* Focus on the articles\n",
    "* Check the test urls are accessible and show v2\n",
    "* If AMP is enabled, test that control urls show v1 AMP and test urls show v2\n",
    "* Check the canonicals\n",
    "* Check the breadcrumbs\n",
    "* That cloudflare looks to be working\n",
    "\n",
    "\n",
    "Out of scope:\n",
    "\n",
    "* That an AMP page is valid AMP (we have a separate test suite for this)\n",
    "* Being robust to html that isn't what's expected during blog v2 launch!\n",
    "* Testing non-article pages (home page, category page etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_test = \"id\"\n",
    "test_staging = True\n",
    "\n",
    "test_urls_csv_filepath = {  # These originally come from https://docs.google.com/spreadsheets/d/1UdrncwVdObaA6d0lnvbAQCHBpQMzEhWPz5OTR9Syobo/edit#gid=0\n",
    "    \"id\":\"./SEO Test Urls/id_seo_test_urls.csv\",\n",
    "    \"tw\":\"./SEO Test Urls/tw_seo_test_urls.csv\",\n",
    "    \"sg\": None,\n",
    "    \"hk\": None,\n",
    "}\n",
    "\n",
    "staging_url_replace_map = {\n",
    "    \"id\": [\"www.moneysmart.id\", \"www.msiddev.com\"],\n",
    "    \"tw\":[\"www.moneysmart.id\", \"www.msiddev.com\"],\n",
    "    \"sg\": [\"blog.moneysmart.sg\",\"blog.mssgdev.com\"],\n",
    "    \"hk\":[\"www.moneysmart.hk\", \"blog.mshkdev.com\"],\n",
    "}\n",
    "\n",
    "post_sitemaps = { #yes, we could load some more dynamically but it saves some coding\n",
    "    \"id\": [\"https://www.moneysmart.id/post-sitemap%i.xml\"%i for i in range(1,13)],\n",
    "    \"tw\": [\"https://www.moneysmart.tw/post-sitemap.xml\"],\n",
    "    \"sg\": [\"https://blog.moneysmart.sg/post-sitemap%i.xml\"%i for i in range(1,5)],\n",
    "    \"hk\": [\"https://blog.moneysmart.hk/post-sitemap%i.xml\"%i for i in range(1,3)],\n",
    "    \n",
    "    #Aside, there seems to be public pages for the ads in the sitemap :( \n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test URL Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping first line of url file: ['url']\n",
      "Found 50 test urls to check for\n"
     ]
    }
   ],
   "source": [
    "def load_seo_test_urls(country_code):\n",
    "    filepath = test_urls_csv_filepath[country_code]\n",
    "    urls = []\n",
    "    with open(filepath) as f:\n",
    "        csv_reader = csv.reader(f, delimiter=',')\n",
    "        for i, row in enumerate(csv_reader):\n",
    "            if i==0:\n",
    "                print(\"Skipping first line of url file: %s\"%row)\n",
    "                continue\n",
    "            urls.append(row[0].strip())\n",
    "\n",
    "    return urls\n",
    "\n",
    "seo_test_urls = load_seo_test_urls(country_to_test)\n",
    "\n",
    "print(\"Found %i test urls to check for\" % len(seo_test_urls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Posts from Sitemaps (and test sitemap works!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading urls from sitemap 0 of 12 https://www.moneysmart.id/post-sitemap1.xml\n",
      "Loading urls from sitemap 1 of 12 https://www.moneysmart.id/post-sitemap2.xml\n",
      "Loading urls from sitemap 2 of 12 https://www.moneysmart.id/post-sitemap3.xml\n",
      "Loading urls from sitemap 3 of 12 https://www.moneysmart.id/post-sitemap4.xml\n",
      "Loading urls from sitemap 4 of 12 https://www.moneysmart.id/post-sitemap5.xml\n",
      "Loading urls from sitemap 5 of 12 https://www.moneysmart.id/post-sitemap6.xml\n",
      "Loading urls from sitemap 6 of 12 https://www.moneysmart.id/post-sitemap7.xml\n",
      "Loading urls from sitemap 7 of 12 https://www.moneysmart.id/post-sitemap8.xml\n",
      "Loading urls from sitemap 8 of 12 https://www.moneysmart.id/post-sitemap9.xml\n",
      "Loading urls from sitemap 9 of 12 https://www.moneysmart.id/post-sitemap10.xml\n",
      "Loading urls from sitemap 10 of 12 https://www.moneysmart.id/post-sitemap11.xml\n",
      "Loading urls from sitemap 11 of 12 https://www.moneysmart.id/post-sitemap12.xml\n",
      "Found 11164 posts in the sitemap\n"
     ]
    }
   ],
   "source": [
    "def get_urls_from_sitemap(sitemap_url):\n",
    "    \n",
    "    r = requests.get(sitemap_url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\") #html parser does xml fine\n",
    "    urls = [element.text for element in soup.findAll('loc')]\n",
    "    return urls\n",
    "\n",
    "def get_all_post_urls_from_sitemap(country_code):\n",
    "    sitemaps = post_sitemaps[country_code]\n",
    "    all_urls = []\n",
    "    for i, sitemap in enumerate(sitemaps):\n",
    "        print(\"Loading urls from sitemap %i of %i %s\" % (i, len(sitemaps), sitemap))\n",
    "        sitemap_urls = get_urls_from_sitemap(sitemap)\n",
    "        all_urls+=sitemap_urls\n",
    "    return all_urls\n",
    "\n",
    "all_post_urls = get_all_post_urls_from_sitemap(country_to_test)\n",
    "\n",
    "print(\"Found %i posts in the sitemap\"%len(all_post_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That leaves 11114 post urls that aren't in the test\n"
     ]
    }
   ],
   "source": [
    "non_test_urls = list(set(all_post_urls) - set(seo_test_urls))\n",
    "print(\"That leaves %i post urls that aren't in the test\" % len(non_test_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-0d64d444c42d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-0d64d444c42d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    >>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_all_post_urls_from_sitemap(country_code):\n",
    "    >>\n",
    "    \n",
    "    \n",
    "def is_amp_page(url, page_cache):\n",
    "    \"\"\"\n",
    "    Very basic test on whether the page is marked in the html tag as AMP\n",
    "    \n",
    "       # <html ⚡> or <html amp>\n",
    "    \"\"\"\n",
    "    soup = page_cache.get_soup(url)\n",
    "    html_tag = soup.find('html')\n",
    "    html_tag.attrs\n",
    "    \n",
    "    if \"amp\" in html_tag.attrs or \"⚡\" in html_tag.attrs:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "def is_v2_page(url, page_cache):\n",
    "    \n",
    "    \n",
    "def is_v2_amp_page(url, page_cache):\n",
    "    \n",
    "    \n",
    "def extract_link_to_amp_version(url, page_cache):\n",
    "    \"\"\"\n",
    "    Returns none if the amp version can't be found\n",
    "    \"\"\"\n",
    "    >>\n",
    "    \n",
    "def extract_breadcrumbs(url, page_cache):\n",
    "    >>\n",
    "    \n",
    "def extract_canonical_tag(url, page_cache):\n",
    "    >>\n",
    "    \n",
    "    \n",
    "def extract_blogposting_structured_data(url, page_cache):\n",
    "    >>\n",
    "    \n",
    "class PageCache(object):\n",
    "    \"\"\"\n",
    "    This is an abstraction for getting a url, which understands\n",
    "    translation between staging and production, authentication etc\n",
    "    and uses a cache to allow efficient repeat requests.\n",
    "    (and whether that cache is in memory, or not is academic)\n",
    "    \n",
    "    It also includes throttling.\n",
    "    \n",
    "    The result might be a redirect to say www3 or whatever.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._page_cache_dict = {} #url:[page_html, load_time, cloudflare_in_headers, cloudflare_hit, url_after_redirect]\n",
    "        self._soup_cache_dict = {} #url: beautifulsoup\n",
    "        self._page_load_time_dict = {} # a log of how long it takes to load the pages in seconds\n",
    "        self.last_page_request_time = datetime.now()\n",
    "        self.min_seconds_between_server_requests = 0.5 #currently after request completion, rather than start\n",
    "    \n",
    "    def get_html(self, url):\n",
    "        \"\"\"\n",
    "        This gets the url, but only requests it if it isn't in the page cache currently\n",
    "        \"\"\"\n",
    "        \n",
    "        seconds_since_last_request = ()\n",
    "        \n",
    "        >>\n",
    "        self.last_page_request_time = datetime.now()\n",
    "        \n",
    "    def get_soup(self, url):\n",
    "        \"\"\"\n",
    "        Returns the beautifulsoup version of the page for tag extraction\n",
    "        \"\"\"\n",
    "        if url not in self._soup_cache_dict:\n",
    "            html = self.get_html(url)\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            self._soup_cache_dict[url] = soup\n",
    "\n",
    "        return self._soup_cache_dict[url]\n",
    "        \n",
    "\n",
    "        \n",
    "    def _download_url_and_cache(self, url):\n",
    "        r = requests.get(url)\n",
    "        \n",
    "        r.raise_for_status() #Throw an exception if get e.g. a 404.\n",
    "        \n",
    "        load_time = r.elapsed.total_seconds()\n",
    "        text = r.text\n",
    "        headers = r.headers\n",
    "        \n",
    "        # Look at headers to judge if caching on the html is working\n",
    "        is_cdn_caching = False\n",
    "        is_cdn_cache_hit = False\n",
    "        if \"Server\" in headers:\n",
    "            if headers[\"Server\"]==\"cloudflare\":\n",
    "                is_cdn_caching = True\n",
    "                if headers[\"cf-cache-status\"]==\"HIT\":\n",
    "                    is_cdn_cache_hit = True\n",
    "            \n",
    "\n",
    "        url_after_redirect = r.url\n",
    "        #\"cf-cache-status\" \"HIT\"  /\"EXPIRED\"\n",
    "        #\"server:cloudflare\"\n",
    "        \n",
    "        self._page_cache_dict[url] = text, load_time, is_cdn_caching, is_cdn_cache_hit, url_after_redirect\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 10, 26, 15, 15, 0, 956878)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www3.moneysmart.id/tas-hermes-mahal-ini-sebabnya/?forceTest=test\")\n",
    "r_amp = requests.get(\"https://www3.moneysmart.id/tas-hermes-mahal-ini-sebabnya/?amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Sat, 26 Oct 2019 15:52:12 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Set-Cookie': '__cfduid=d08f2c1f5389267ebc10d143f9c84b2901572105132; expires=Sun, 25-Oct-20 15:52:12 GMT; path=/; domain=.moneysmart.id; HttpOnly; Secure, ms_experiment_wa0051={MS-046:test}; path=/; domain=moneysmart.id', 'CF-Cache-Status': 'HIT', 'Cache-Control': 'public, max-age=3600, s-maxage=3600', 'CF-Ray': '52bd98934edfaa1e-SIN', 'Age': '7', 'Expect-CT': 'max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"', 'Vary': 'Accept-Encoding', 'Server': 'cloudflare', 'Content-Encoding': 'gzip'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n<html data-n-head-ssr lang=\"id-ID\" data-n-head=\"lang\">\\n<head data-n-head=\"\">\\n<title '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r_amp.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_tag = soup.find('html')\n",
    "html_tag.attrs\n",
    "list(range(1,13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Homepage still loads!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the AB split percentage (approximately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Test Articles are v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Test Articles have v2 AMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Cloudflare is (to some extent) Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
